#!/usr/bin/env python3
"""
Test improved stopwords and Unicode normalization
"""

def test_improved_filtering():
    """Test the enhanced stopword filtering"""
    print("ğŸ§ª Testing Enhanced Stopword Filtering...")

    from nepali_text_processor import NepaliTextProcessor
    from improved_wordcloud_generator import ImprovedWordCloudGenerator

    processor = NepaliTextProcessor()

    # Test text with known problematic words
    test_text = """
    à¤¨à¥‡à¤ªà¤¾à¤² à¤¸à¤°à¤•à¤¾à¤°à¤²à¥‡ à¤ªà¥à¤°à¤§à¤¾à¤¨à¤®à¤¨à¥à¤¤à¥à¤°à¥€ à¤ªà¤¨à¤¿ à¤›à¤¨à¥ à¤²à¤¾à¤—à¤¿ à¤—à¤°à¥à¤¨ à¤®à¤¨à¥à¤¤à¥à¤°à¥€ à¤¨à¥‡à¤¤à¥ƒà¤¤à¥à¤µà¤®à¤¾ à¤•à¤¾à¤°à¥à¤¯à¤•à¥à¤°à¤® à¤†à¤¯à¥‹à¤œà¤¨à¤¾ à¤—à¤°à¥à¤¯à¥‹à¥¤
    à¤•à¤¾à¤ à¤®à¤¾à¤¡à¥Œà¤‚à¤®à¤¾ à¤°à¤¾à¤œà¤¨à¥€à¤¤à¤¿à¤• à¤¦à¤²à¤¹à¤°à¥‚à¤•à¥‹ à¤¬à¥ˆà¤ à¤• à¤­à¤¯à¥‹à¥¤ à¤¨à¤¿à¤°à¥à¤µà¤¾à¤šà¤¨ à¤†à¤¯à¥‹à¤—à¤²à¥‡ à¤¤à¤¯à¤¾à¤°à¥€ à¤¸à¥à¤°à¥ à¤—à¤°à¥‡à¤•à¥‹ à¤›à¥¤
    à¤µà¤¿à¤•à¤¾à¤¸ à¤¨à¤¿à¤°à¥à¤®à¤¾à¤£à¤•à¤¾ à¤•à¤¾à¤® à¤›à¤¨à¥ à¤ªà¤¨à¤¿ à¤…à¤¬ à¤—à¤°à¥à¤¨ à¤²à¤¾à¤—à¤¿ à¤­à¤à¤•à¥‹ à¤›à¥¤
    """

    print(f"ğŸ“ Test text: {test_text}")

    # Extract words before and after
    print("\nğŸ” BEFORE Enhancement:")
    words_before = test_text.split()
    print(f"All words: {words_before}")

    print("\nğŸ” AFTER Enhancement:")
    meaningful_words = processor.extract_devanagari_words(test_text)
    print(f"Meaningful words: {meaningful_words}")

    # Check which words were filtered
    filtered_out = set(words_before) - set(meaningful_words)
    print(f"\nâŒ Filtered out: {filtered_out}")

    # Generate word cloud
    print("\nğŸ¨ Generating improved word cloud...")
    generator = ImprovedWordCloudGenerator()
    wordcloud = generator.generate_from_text(test_text)

    if wordcloud:
        generator.save_wordcloud(wordcloud, 'improved_stopwords_test.png')

        top_words = list(wordcloud.words_.keys())[:10]
        print(f"âœ… Top words in cloud: {top_words}")

        # Check for problematic words
        problematic_words = {'à¤ªà¤¨à¤¿', 'à¤›à¤¨à¥', 'à¤—à¤°à¥à¤¨', 'à¤²à¤¾à¤—à¤¿', 'à¤­à¤à¤•à¥‹', 'à¤—à¤°à¥‡à¤•à¥‹'}
        found_problematic = [word for word in top_words if word in problematic_words]

        if found_problematic:
            print(f"âš ï¸ Still found problematic words: {found_problematic}")
        else:
            print("âœ… No problematic stopwords in top results!")

        return True
    else:
        print("âŒ Word cloud generation failed")
        return False

def create_comparison_cloud():
    """Create comparison with database content"""
    print("\nğŸ§ª Creating Database Content Comparison...")

    from improved_wordcloud_generator import ImprovedWordCloudGenerator

    generator = ImprovedWordCloudGenerator()

    # Generate from actual database
    wordcloud = generator.generate_from_database(limit=30)

    if wordcloud:
        generator.save_wordcloud(wordcloud, 'enhanced_database_wordcloud.png')

        top_words = list(wordcloud.words_.keys())[:15]
        print(f"ğŸ¯ Database top words: {top_words}")

        # Analyze word quality
        print("\nğŸ“Š Word Quality Analysis:")
        meaningful_count = 0
        stopword_count = 0
        single_char_count = 0

        stopwords = {'à¤ªà¤¨à¤¿', 'à¤›à¤¨à¥', 'à¤—à¤°à¥à¤¨', 'à¤²à¤¾à¤—à¤¿', 'à¤­à¤à¤•à¥‹', 'à¤—à¤°à¥‡à¤•à¥‹', 'à¤¹à¥à¤¨à¥‡', 'à¤­à¤¨à¥‡', 'à¤›', 'à¤¹à¥‹'}

        for word in top_words:
            if len(word) == 1:
                single_char_count += 1
                print(f"   âŒ Single character: {word}")
            elif word in stopwords:
                stopword_count += 1
                print(f"   âš ï¸  Stopword: {word}")
            else:
                meaningful_count += 1
                print(f"   âœ… Meaningful: {word}")

        print(f"\nğŸ“ˆ Quality Score: {meaningful_count}/{len(top_words)} meaningful words")
        print(f"   â€¢ Meaningful: {meaningful_count}")
        print(f"   â€¢ Stopwords: {stopword_count}")
        print(f"   â€¢ Single chars: {single_char_count}")

        return meaningful_count >= len(top_words) * 0.7  # 70% meaningful threshold

    return False

if __name__ == "__main__":
    print("ğŸš€ Testing Enhanced Nepali Text Processing")
    print("=" * 50)

    test1 = test_improved_filtering()
    test2 = create_comparison_cloud()

    print("\n" + "=" * 50)
    print("ğŸ“Š RESULTS:")

    if test1:
        print("âœ… Stopword filtering test: PASSED")
    else:
        print("âŒ Stopword filtering test: FAILED")

    if test2:
        print("âœ… Database word quality test: PASSED")
    else:
        print("âŒ Database word quality test: FAILED")

    if test1 and test2:
        print("\nğŸ‰ All improvements working correctly!")
        print("ğŸ“ Check generated files:")
        print("   â€¢ improved_stopwords_test.png")
        print("   â€¢ enhanced_database_wordcloud.png")
    else:
        print("\nâš ï¸ Some issues remain. Check individual test results above.")